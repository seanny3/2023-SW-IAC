{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:55<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os, random\n",
    "from shutil import copytree, copyfile\n",
    "\n",
    "aaa = 0\n",
    "nc = 136\n",
    "            \n",
    "target = \"C:\\\\workspace\\\\hyundai_dataset\\\\4_all\"\n",
    "output = \"C:\\\\workspace\\\\hyundai_dataset\\\\5_reduce\"\n",
    "\n",
    "for model in tqdm(os.listdir(target)):\n",
    "    labels = glob(os.path.join(target, model)+\"/*.txt\")\n",
    "    n = len(labels)\n",
    "    \n",
    "    if n >= 50 and n <= 200:\n",
    "        copytree(os.path.join(target, model), os.path.join(output, model))\n",
    "\n",
    "    if n > 200:\n",
    "        for sam in random.sample(labels, 200):\n",
    "            label = Path(sam)\n",
    "            img = label.with_suffix('.jpg')\n",
    "\n",
    "            save_dir = img.stem.split(\"_\")[0]\n",
    "            if not os.path.exists(os.path.join(output, save_dir)):\n",
    "                os.mkdir(os.path.join(output, save_dir))\n",
    "\n",
    "            copyfile(img, Path(os.path.join(output, save_dir)) / img.name)\n",
    "            copyfile(label, Path(os.path.join(output, save_dir)) / label.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_hyundai_atos-(MIX): 58\n",
      "1_hyundai_casper-(AX1): 50\n",
      "9_hyundai_accent-(RB): 168\n",
      "11_hyundai_i30-(FD): 62\n",
      "12_hyundai_i30-(GD): 77\n",
      "25_hyundai_new-avante-XD: 131\n",
      "26_hyundai_avante-HD: 480\n",
      "28_hyundai_avante-MD: 680\n",
      "30_hyundai_the-new-avante-MD: 248\n",
      "31_hyundai_avante-AD: 551\n",
      "32_hyundai_the-new-avante-AD: 91\n",
      "33_hyundai_avante-(CN7): 255\n",
      "37_hyundai_ioniq-HEV-(AE): 66\n",
      "38_hyundai_ioniq-EV-(AE): 98\n",
      "47_hyundai_tucson-(JM): 121\n",
      "48_hyundai_tucson-ix-(LM): 347\n",
      "49_hyundai_new-tucson-ix-(LM): 201\n",
      "50_hyundai_tucson-(TL): 372\n",
      "51_hyundai_the-all-new-tucson-(NX4): 74\n",
      "52_hyundai_nexo-(FE): 70\n",
      "54_hyundai_santa-fe-(CM): 413\n",
      "55_hyundai_santa-fe-(DM): 656\n",
      "56_hyundai_santa-fe-the-prime-(DM): 115\n",
      "57_hyundai_santa-fe-(TM): 299\n",
      "58_hyundai_the-new-santa-fe-(TM): 208\n",
      "62_hyundai_veracruz-(EN): 195\n",
      "63_hyundai_maxcruz-(NC): 82\n",
      "64_hyundai_the-new-maxcruz-(NC): 131\n",
      "65_hyundai_palisade-(LX2): 301\n",
      "66_hyundai_the-new-palisade-(LX2): 107\n",
      "71_hyundai_staria-(US4): 58\n",
      "75_hyundai_starex-(TQ): 435\n",
      "76_hyundai_the-new-grand-starex-(TQ): 263\n",
      "79_hyundai_porter2-(HR): 1403\n",
      "82_hyundai_solati-(EU): 85\n",
      "88_hyundai_ioniq5-(NE): 174\n",
      "91_hyundai_new-EF-sonata: 57\n",
      "92_hyundai_NF-sonata: 279\n",
      "93_hyundai_NF-sonata-transform: 241\n",
      "94_hyundai_YF-sonata: 757\n",
      "95_hyundai_YF-sonata-HEV: 74\n",
      "96_hyundai_LF-sonata: 443\n",
      "97_hyundai_LF-sonata-HEV: 82\n",
      "99_hyundai_LF-sonata-new-rise: 276\n",
      "101_hyundai_sonata-(DN8): 201\n",
      "102_hyundai_ioniq6-(CE): 103\n",
      "108_hyundai_the-luxury-grandeur-TG: 98\n",
      "109_hyundai_grandeur-HG: 938\n",
      "110_hyundai_grandeur-HG-HEV: 468\n",
      "111_hyundai_grandeur-IG: 995\n",
      "112_hyundai_the-new-grandeur-IG: 681\n",
      "113_hyundai_the-all-new-grandeur-(GN7): 131\n",
      "118_hyundai_new-equus-(VI): 114\n",
      "127_hyundai_venue-(QX): 86\n",
      "129_hyundai_kona-(OS): 171\n",
      "130_hyundai_kona-(OS)-EV: 169\n",
      "135_hyundai_grandeur-TG: 497\n",
      "57\n",
      "8498\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "b=0\n",
    "for c, n in enumerate(classes):\n",
    "    if int(n[1]) >= 50:\n",
    "    # print(f\"{n[1]}\")\n",
    "        print(f\"{c}_{n[0]}: {n[1]}\")\n",
    "        a = a+1\n",
    "        if n[1] > 200: b = b+200\n",
    "        else: b = b+n[1]\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스 인덱스 초과 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "cls_num = 136\n",
    "\n",
    "# classes.txt 빼기\n",
    "labels = list(map(Path, glob('C:\\\\workspace\\\\hyundai_dataset\\\\4_all\\\\**\\\\*.txt')))\n",
    "labels = list(filter(lambda item: item.name != 'classes.txt', labels))\n",
    "\n",
    "for label in tqdm(labels):\n",
    "    with open(label, 'r') as file:\n",
    "        for line in file:\n",
    "            columns = line.split()\n",
    "            if int(columns[0]) >= cls_num:\n",
    "                print(label)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스 중복 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2413/2413 [00:43<00:00, 54.87it/s] \n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# classes.txt 빼기\n",
    "labels = list(map(Path, glob('C:\\\\workspace\\\\hyundai_dataset\\\\4_all\\\\**\\\\*.txt')))\n",
    "labels = list(filter(lambda item: item.name != 'classes.txt', labels))\n",
    "\n",
    "remove_list = []\n",
    "for label in tqdm(labels):\n",
    "    with open(label, 'r') as file:\n",
    "        cnt = 0\n",
    "        for line in file:\n",
    "            cnt += 1\n",
    "        if cnt >= 2:\n",
    "            print(label)\n",
    "            # remove_list.append(label)\n",
    "\n",
    "# for item in remove_list:\n",
    "#     os.remove(str(item.with_suffix('.jpg')))\n",
    "#     os.remove(str(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from glob import glob\n",
    "# from pathlib import Path\n",
    "\n",
    "# # classes.txt 빼기\n",
    "# labels = list(map(Path, glob('./data/img/*txt')))\n",
    "# labels = list(filter(lambda item: item.name != 'classes.txt', labels))\n",
    "\n",
    "# _from = 1\n",
    "# _to = 2\n",
    "\n",
    "# for label in labels:\n",
    "#     with open(label, 'r') as file:\n",
    "#         lines = file.readlines()\n",
    "\n",
    "#     with open(label, 'w') as file:\n",
    "#         for line in lines:\n",
    "#             columns = line.strip().split()  # 공백으로 분리된 컬럼 추출\n",
    "#             if columns and columns[0] == str(_from):\n",
    "#                 columns[0] = str(_to)\n",
    "#             new_line = ' '.join(columns) + '\\n'\n",
    "#             file.write(new_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스 이름과 파일명 동일하게 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 7748/17786 [02:00<03:48, 43.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\05-07-08-09\\hyundai+avante-HD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 8449/17786 [02:16<03:35, 43.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\05-07-08-09\\hyundai+LF-sonata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 8473/17786 [02:16<03:04, 50.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\05-07-08-09\\hyundai+LF-sonata-PHEV\n",
      "C:\\workspace\\hyundai_dataset\\test\\05-07-08-09\\hyundai+LF-sonata-PHEV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9436/17786 [02:37<02:30, 55.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\05-07-08-09\\hyundai+the-all-new-grandeur-(GN7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17786/17786 [04:11<00:00, 70.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import time, uuid, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# classes.txt 빼기\n",
    "labels = list(map(Path, glob('C:\\\\workspace\\\\hyundai_dataset\\\\test\\\\**\\\\**\\\\*.txt')))\n",
    "labels = list(filter(lambda item: item.name != 'classes.txt', labels))\n",
    "\n",
    "classes = []\n",
    "with open('./classes.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        classes.append(line.split()[0])\n",
    "a=0\n",
    "for label in tqdm(labels):\n",
    "    new_name = None\n",
    "    root = Path(label).parent\n",
    "    with open(label, 'r') as file:\n",
    "        cnt = 0\n",
    "        for line in file:\n",
    "            if cnt >= 1:\n",
    "                continue\n",
    "\n",
    "            columns = line.split()\n",
    "            new_str = classes[int(columns[0])].split('_')\n",
    "            new_name = f\"{new_str[0]}+{new_str[1]}_{int(time.time())}{str(uuid.uuid4().hex[:8])}\"\n",
    "            \n",
    "            a+=1\n",
    "            cnt += 1\n",
    "    \n",
    "    if new_name is None:\n",
    "        new_name = f\"background_{int(time.time())}{str(uuid.uuid4().hex[:8])}\"\n",
    "    try:\n",
    "        # image.jpg 이름 변경\n",
    "        os.rename(str(label.with_suffix('.jpg')), root / f\"{new_name}.jpg\")\n",
    "        # label.txt 이름 변경               \n",
    "        os.rename(str(label), root / f\"{new_name}.txt\")\n",
    "    except:\n",
    "        print(root)\n",
    "        continue;\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category 별로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 258/17805 [00:00<00:47, 372.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\04\\avante-AD\\avante-AD_1698325642fb23b0e1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2364/17805 [00:54<06:11, 41.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\04\\i30-(FD)\\i30-(FD)_1698325571d2e24af8.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\i30-(FD)\\i30-(FD)_1698325657eab5881f.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 3335/17805 [01:20<05:42, 42.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\04\\mighty-(WQ)\\mighty-(WQ)_16983255883b78b723.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\mighty-(WQ)\\mighty-(WQ)_16983255890fd8978b.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\mighty-(WQ)\\mighty-(WQ)_16983256402404257a.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\mighty-(WQ)\\mighty-(WQ)_169832567719fbc86e.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3431/17805 [01:22<06:08, 38.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\04\\new-EF-sonata\\new-EF-sonata_1698325598883032f3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 3473/17805 [01:23<06:02, 39.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\04\\new-grandeur-XG\\new-grandeur-XG_16983256417e6c01d7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 3654/17805 [01:28<05:28, 43.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\04\\nexo-(FE)\\nexo-(FE)_169832557710053455.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 3731/17805 [01:30<07:24, 31.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\04\\NF-sonata\\NF-sonata_16983255907167913c.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\NF-sonata\\NF-sonata_1698325611168572e0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5187/17805 [02:07<06:50, 30.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\04\\santa-fe-(SM)\\santa-fe-(SM)_1698325576e7bf09a8.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 5667/17805 [02:20<06:05, 33.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\04\\terracan-(HP)\\terracan-(HP)_169832557157e4bf6d.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\terracan-(HP)\\terracan-(HP)_1698325595c1820cbc.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\terracan-(HP)\\terracan-(HP)_1698325598d529ee95.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\terracan-(HP)\\terracan-(HP)_1698325604e3da6b91.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\terracan-(HP)\\terracan-(HP)_1698325618c7752b7c.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\terracan-(HP)\\terracan-(HP)_16983256399a166743.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\terracan-(HP)\\terracan-(HP)_16983256451e0546f3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 5675/17805 [02:20<06:31, 31.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\04\\terracan-(HP)\\terracan-(HP)_1698325693cad95af1.txt\n",
      "C:\\workspace\\hyundai_dataset\\test\\04\\terracan-(HP)\\terracan-(HP)_1698325697f9a8cb62.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6690/17805 [02:45<04:36, 40.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\04\\the-new-santa-fe-(TM)\\the-new-santa-fe-(TM)_1698325571a5ce23b9.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 8452/17805 [03:30<03:49, 40.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hyundai_dataset\\test\\05-07-08-09\\hyundai+LF-sonata\\hyundai+LF-sonata_1698320878607d3fb8.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17805/17805 [05:45<00:00, 51.53it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "files = [Path(img) for img in glob('C:\\\\workspace\\\\hyundai_dataset\\\\test\\\\**\\\\**\\\\*.jpg')]\n",
    "\n",
    "output = \"C:\\\\workspace\\\\hyundai_dataset\\\\test\\\\output\"\n",
    "if not os.path.exists(output):\n",
    "    os.mkdir(output)\n",
    "\n",
    "for image in tqdm(files):\n",
    "    label = image.with_suffix('.txt')\n",
    "    save_dir = str(image.stem).split('_')[0]\n",
    "\n",
    "    if not os.path.exists(os.path.join(output, save_dir)):\n",
    "        os.mkdir(os.path.join(output, save_dir))\n",
    "    \n",
    "    try:\n",
    "        copyfile(image, os.path.join(output, save_dir, image.name))\n",
    "        copyfile(label, os.path.join(output, save_dir, label.name))\n",
    "    except:\n",
    "        print(label)\n",
    "        continue;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGBA to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 582/8264 [00:08<04:10, 30.65it/s] c:\\Users\\User\\anaconda3\\envs\\py3.8\\lib\\site-packages\\PIL\\Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 89%|████████▊ | 7333/8264 [02:29<00:13, 70.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\hyundai_category\\hyundai+tucson-(JM)\\hyundai+tucson-(JM)_1693204778f59175ef.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8264/8264 [02:47<00:00, 49.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "files = [Path(img) for img in glob('C:\\\\Users\\\\User\\\\Desktop\\\\hyundai_category\\\\**\\\\*.jpg')]\n",
    "\n",
    "if not os.path.exists('output'):\n",
    "    os.mkdir('output')\n",
    "    \n",
    "for file in tqdm(files):\n",
    "    try:\n",
    "        img = Image.open(str(file)).convert('RGB')\n",
    "        img.save(os.path.join('output', file.name))\n",
    "    except:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 테스트 파일 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "from pathlib import Path\n",
    "\n",
    "dataset = 'C:\\\\workspace\\\\데이터셋\\\\3_완료\\\\06'\n",
    "target_dir = './test/dataset/'\n",
    "\n",
    "export_n = 10   # 클래스 당 몇 개 추출할 것인가?\n",
    "\n",
    "for cls_name in os.listdir(dataset):\n",
    "    cls_dir = os.path.join(dataset, cls_name)\n",
    "    labels = list(filter(lambda a: a.split('.')[1] == 'txt' , os.listdir(cls_dir)))\n",
    "    for label in labels[:export_n]:\n",
    "        label_dir = os.path.join(cls_dir, label)\n",
    "        img = Path(label).with_suffix('.jpg')\n",
    "        img_dir = os.path.join(cls_dir, img)\n",
    "        copyfile(label_dir, os.path.join('./test/정답/', label))\n",
    "        copyfile(img_dir, os.path.join(target_dir, img))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/849 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 849/849 [00:00<00:00, 9057.82it/s]\n",
      "100%|██████████| 849/849 [00:05<00:00, 154.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817/849\n",
      "96.23085983510012%\n",
      "error: 3.0683156654888104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    height = []\n",
    "    with open('./test/height.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        numbers = []\n",
    "        for line in lines:\n",
    "            height.append(int(line.split()[0]))\n",
    "    \n",
    "    folder1 = glob('./test/correct/*.txt')\n",
    "    folder2 = glob('./test/predict/*.txt')\n",
    "    \n",
    "    f1_list = []\n",
    "    f2_list = []\n",
    "    for f1 in tqdm(folder1):\n",
    "        try:\n",
    "            with open(f1, 'r') as f:\n",
    "                lines = f.read()\n",
    "                line = lines.split()\n",
    "                f1_list.append(line[0])\n",
    "        except:\n",
    "            f1_list.append(999)\n",
    "\n",
    "    for f2 in tqdm(folder2):\n",
    "        try:\n",
    "            with open(f2, 'r') as f:\n",
    "                lines = f.read()\n",
    "                line = lines.split()\n",
    "                f2_list.append(line[0])\n",
    "        except:\n",
    "            f2_list.append(' ')\n",
    "            \n",
    "    cnt = 0\n",
    "    for idx, item in enumerate(f1_list, 0):\n",
    "        if f2_list[idx] == f1_list[idx]:\n",
    "            cnt += 1\n",
    "\n",
    "    error = []\n",
    "    for idx, item in enumerate(f1_list, 0):\n",
    "        try:\n",
    "            error.append(abs(height[int(f2_list[idx])]-height[int(f1_list[idx])]))\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    print(f\"{cnt}/{len(f1_list)}\")\n",
    "    print(f\"{cnt/len(f1_list)*100}%\")\n",
    "    print(f\"error: {float(sum(error))/len(error)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 오차 계산"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
